

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="zh-CN" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="zh-CN" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Set up a single node cluster with Hadoop* &mdash; Documentation for Clear Linux* project</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript">
          var DOCUMENTATION_OPTIONS = {
              URL_ROOT:'../',
              VERSION:'',
              LANGUAGE:'zh_CN',
              COLLAPSE_INDEX:false,
              FILE_SUFFIX:'.html',
              HAS_SOURCE:  true,
              SOURCELINK_SUFFIX: '.txt'
          };
      </script>
        <script type="text/javascript" src="../_static/jquery.js"></script>
        <script type="text/javascript" src="../_static/underscore.js"></script>
        <script type="text/javascript" src="../_static/doctools.js"></script>
        <script type="text/javascript" src="../_static/translations.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="index" title="索引" href="../genindex.html" />
    <link rel="search" title="搜索" href="../search.html" />
    <link rel="next" title="Use the function multi-version patch generator" href="fmv.html" />
    <link rel="prev" title="Run Clear Linux* OS using Microsoft Azure CLI 2.0" href="azure.html" />

<link rel="stylesheet" href="../_static/tcs_theme.css" type="text/css" />


</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: #007ab2" >
          

          
            <a href="../index.html" class="icon icon-home"> Clear Linux* Project Docs
          

          
            
            <img src="../_static/clearlinux.png" class="logo" alt="Logo"/>
          
          </a>

          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
  
  <div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
    <span class="rst-current-version" data-toggle="rst-current-version">
      <span class="fa fa-book"> Clear Linux</span>
      v: latest
      <span class="fa fa-caret-down"></span>
    </span>
    <div class="rst-other-versions">
      <dl>
        <dt>Language Versions</dt>
        
          <dd><a href="/clearlinux/tutorials/hadoop.html">English</a></dd>
        
          <dd><a href="/clearlinux/zh_CN/tutorials/hadoop.html">Chinese</a></dd>
        
      </dl>
      <dl>
        <dt>Document Versions</dt>
        
          <dd><a href="/clearlinux/tutorials/hadoop.html">latest</a></dd>
        
          <dd><a href="/clearlinux/L19.01/tutorials/hadoop.html">L19.01</a></dd>
        
      </dl>
      <dl>
        <dt>clearlinux.org links</dt>
          <dd>
            <a href="https://www.clearlinux.org/">Project Home</a>
          </dd>
          <dd>
            <a href="https://github.com/clearlinux/clear-linux-documentation">GitHub</a>
          </dd>
      </dl>
    </div>
  </div>
  
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../get-started/get-started.html">Get started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tooling/tooling.html">How to Clear</a></li>
<li class="toctree-l1"><a class="reference internal" href="../guides/guides.html">Guides</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="tutorials.html">Tutorials</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="wordpress/wordpress.html">WordPress* on Clear Linux* OS</a></li>
<li class="toctree-l2"><a class="reference internal" href="flatpak/flatpak.html">Use Flatpak* to install applications on Clear Linux* OS</a></li>
<li class="toctree-l2"><a class="reference internal" href="machine-learning/machine-learning.html">TensorFlow* machine learning on Clear Linux* OS</a></li>
<li class="toctree-l2"><a class="reference internal" href="docker/docker.html">Run Docker* on Clear Linux* OS</a></li>
<li class="toctree-l2"><a class="reference internal" href="azure.html">Run Clear Linux* OS using Microsoft Azure CLI 2.0</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Set up a single node cluster with Hadoop*</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#prerequisites">Prerequisites</a></li>
<li class="toctree-l3"><a class="reference internal" href="#install-apache-hadoop">Install Apache Hadoop</a></li>
<li class="toctree-l3"><a class="reference internal" href="#configure-apache-hadoop">Configure Apache Hadoop</a></li>
<li class="toctree-l3"><a class="reference internal" href="#configure-your-ssh-key">Configure your SSH key</a></li>
<li class="toctree-l3"><a class="reference internal" href="#run-the-hadoop-daemons">Run the Hadoop daemons</a></li>
<li class="toctree-l3"><a class="reference internal" href="#run-the-mapreduce-wordcount-example">Run the MapReduce wordcount example</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="fmv.html">Use the function multi-version patch generator</a></li>
<li class="toctree-l2"><a class="reference internal" href="aws-web/aws-web.html">Create and launch Clear Linux* OS from Amazon Web Services</a></li>
<li class="toctree-l2"><a class="reference internal" href="smb/smb.html">Enable simple file sharing with a Windows* machine using Samba*</a></li>
<li class="toctree-l2"><a class="reference internal" href="smb/smb-desktop.html">Connect to Windows* shared location from Clear Linux* OS desktop</a></li>
<li class="toctree-l2"><a class="reference internal" href="spark.html">Set up a standalone cluster system using Apache* Spark*</a></li>
<li class="toctree-l2"><a class="reference internal" href="kata.html">Install Kata Containers*</a></li>
<li class="toctree-l2"><a class="reference internal" href="kata_migration.html">Migrate Clear Containers to Kata Containers*</a></li>
<li class="toctree-l2"><a class="reference internal" href="kubernetes/kubernetes.html">Run Kubernetes*</a></li>
<li class="toctree-l2"><a class="reference internal" href="kubernetes/kubernetes-bp.html">Kubernetes Best Practices on Clear Linux OS</a></li>
<li class="toctree-l2"><a class="reference internal" href="yubikey-u2f.html">Enable YubiKey U2F Support</a></li>
<li class="toctree-l2"><a class="reference internal" href="nvidia.html">Install NVIDIA* Drivers</a></li>
<li class="toctree-l2"><a class="reference internal" href="redis.html">Run Redis on Clear Linux* OS</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorial-proxy.html">Setting up proxy</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../reference/reference.html">Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../FAQ/faq.html">FAQ</a></li>
</ul>

            
          

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Clear Linux* Project Docs</a>
        
      </nav>


      <div class="wy-nav-content">

<header id="header">
  <div class="padding-md--left-right">

    <div class="header__site_info">
           <div class="header__site_info_name">
             <a href ="https://clearlinux.org"> Clear Linux* Project</a>
           </div>
    </div>
    <nav class="header__menu">
        <ul class="header__menu_list">
                         <li class="header__menu_list_item green  ">
                <a tabindex='1' href="https://clearlinux.org/about">About</a>
              </li>
                         <li class="header__menu_list_item purple  ">
                <a tabindex='1' href="https://clearlinux.org/developer">Developer</a>
              </li>
                         <li class="header__menu_list_item blue  ">
                <a tabindex='1' href="https://clearlinux.org/software">Software</a>
              </li>
        </ul>
    </nav>

  </div>



</header>


        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
          <li><a href="tutorials.html">Tutorials</a> &raquo;</li>
        
      <li>Set up a single node cluster with Hadoop*</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            
              <a href="https://github.com/clearlinux/clear-linux-documentation/blob/rtd-theme/source/tutorials/hadoop.rst" class="fa fa-github"> Edit on GitHub</a>
            
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="set-up-a-single-node-cluster-with-hadoop">
<span id="hadoop"></span><h1>Set up a single node cluster with Hadoop*</h1>
<p>This tutorial walks you through the process of installing, configuring, and
running Apache* Hadoop on Clear Linux* OS. The Apache Hadoop software library is a
framework for distributed processing of large data sets across clusters of
computers using simple programming models. It is designed to scale up from
single servers to thousands of machines, with each machine offering local
computation and storage.</p>
<div class="section" id="prerequisites">
<h2>Prerequisites</h2>
<p>Before following this tutorial, you should follow the
<a class="reference internal" href="../get-started/bare-metal-install-desktop/bare-metal-install-desktop.html#bare-metal-install-desktop"><span class="std std-ref">Install Clear Linux* OS from the live desktop</span></a> to ensure you have installed Clear Linux OS.</p>
<p>Before you install any new packages, update Clear Linux OS with the following command:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>sudo swupd update
</pre></div>
</div>
<p>For the purposes of this tutorial, we will install Hadoop in a single machine
running both the master and slave daemons.</p>
</div>
<div class="section" id="install-apache-hadoop">
<h2>Install Apache Hadoop</h2>
<p>Apache Hadoop is included in the <cite>big-data-basic</cite> bundle. To install the
framework, enter the following command:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>sudo swupd bundle-add big-data-basic
</pre></div>
</div>
</div>
<div class="section" id="configure-apache-hadoop">
<h2>Configure Apache Hadoop</h2>
<ol class="arabic">
<li><p class="first">To create the configuration directory, enter the following command:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>sudo mkdir /etc/hadoop
</pre></div>
</div>
</li>
<li><p class="first">Copy the defaults from <code class="file docutils literal notranslate"><span class="pre">/usr/share/defaults/hadoop</span></code> to
<code class="file docutils literal notranslate"><span class="pre">/etc/hadoop</span></code> with the following command:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ sudo cp /usr/share/defaults/hadoop/* /etc/hadoop
</pre></div>
</div>
<div class="admonition note">
<p class="first admonition-title">注解</p>
<p class="last">Since Clear Linux OS is a stateless system, you should never modify the
files under the <code class="file docutils literal notranslate"><span class="pre">/usr/share/defaults</span></code> directory. The software
updater will overwrite those files.</p>
</div>
</li>
</ol>
<p>Once all the configuration files are in <code class="file docutils literal notranslate"><span class="pre">/etc/hadoop</span></code>, we must edit
them to fit our needs. The <cite>NameNode</cite> server is the master server. It manages
the namespace of the files system and regulates the clients’ access to files.
The first file we edit, <code class="file docutils literal notranslate"><span class="pre">/etc/hadoop/core-site.xml</span></code>, informs the Hadoop
daemon where <cite>NameNode</cite> is running.</p>
<p>In this tutorial, our <cite>NameNode</cite> runs in our <cite>localhost</cite>. Follow these steps
to set it up correctly:</p>
<ol class="arabic">
<li><p class="first">Open the <code class="file docutils literal notranslate"><span class="pre">/etc/hadoop/core-site.xml</span></code> file using the editor of your
choice and modify the file as follows:</p>
<div class="highlight-xml notranslate"><div class="highlight"><pre><span></span><span class="cp">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span>
<span class="cp">&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;</span>
<span class="nt">&lt;configuration&gt;</span>
<span class="nt">&lt;property&gt;</span>
<span class="nt">&lt;name&gt;</span>fs.default.name<span class="nt">&lt;/name&gt;</span>
<span class="nt">&lt;value&gt;</span>hdfs://localhost:9000<span class="nt">&lt;/value&gt;</span>
<span class="nt">&lt;/property&gt;</span>
<span class="nt">&lt;/configuration&gt;</span>
</pre></div>
</div>
</li>
<li><p class="first">Edit the <code class="file docutils literal notranslate"><span class="pre">/etc/hadoop/hdfs-site.xml</span></code> file. This file configures the
<abbr title="Hadoop Distributed File System">HDFS</abbr> daemons. This configuration
includes the list of permitted and excluded data nodes and the size of
said blocks. In this example, we are setting the number of block
replication to 1 from the default of 3 as follows:</p>
<div class="highlight-xml notranslate"><div class="highlight"><pre><span></span><span class="cp">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span>
<span class="cp">&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;</span>
<span class="nt">&lt;configuration&gt;</span>
<span class="nt">&lt;property&gt;</span>
<span class="nt">&lt;name&gt;</span>dfs.replication<span class="nt">&lt;/name&gt;</span>
<span class="hll"><span class="nt">&lt;value&gt;</span>1<span class="nt">&lt;/value&gt;</span>
</span><span class="nt">&lt;/property&gt;</span>
<span class="nt">&lt;property&gt;</span>
<span class="nt">&lt;name&gt;</span>dfs.permission<span class="nt">&lt;/name&gt;</span>
<span class="nt">&lt;value&gt;</span>false<span class="nt">&lt;/value&gt;</span>
<span class="nt">&lt;/property&gt;</span>
<span class="nt">&lt;/configuration&gt;</span>
</pre></div>
</div>
</li>
<li><p class="first">Edit the <code class="file docutils literal notranslate"><span class="pre">/etc/hadoop/mapred-site.xml</span></code> file. This file configures
all daemons related to <cite>MapReduce</cite>: <cite>JobTracker</cite> and <cite>TaskTrackers</cite>. With
<cite>MapReduce</cite>, Hadoop can process big amounts of data in multiple systems. In
our example, we set <abbr title="Yet Another Resource Manager">YARN</abbr> as our
runtime framework for executing <cite>MapReduce</cite> jobs as follows:</p>
<div class="highlight-xml notranslate"><div class="highlight"><pre><span></span><span class="cp">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span>
<span class="cp">&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;</span>
<span class="nt">&lt;configuration&gt;</span>
<span class="nt">&lt;property&gt;</span>
<span class="hll"><span class="nt">&lt;name&gt;</span>mapreduce.framework.name<span class="nt">&lt;/name&gt;</span>
</span><span class="hll"><span class="nt">&lt;value&gt;</span>yarn<span class="nt">&lt;/value&gt;</span>
</span><span class="nt">&lt;/property&gt;</span>
<span class="nt">&lt;/configuration&gt;</span>
</pre></div>
</div>
</li>
<li><p class="first">Edit the <code class="file docutils literal notranslate"><span class="pre">/etc/hadoop/yarn-site.xml</span></code> file. This file configures all
daemons related to <cite>YARN</cite>: <cite>ResourceManager</cite> and <cite>NodeManager</cite>. In our
example, we implement the <cite>mapreduce_shuffle</cite> service, which is the
default as follows:</p>
<div class="highlight-xml notranslate"><div class="highlight"><pre><span></span><span class="cp">&lt;?xml version=&quot;1.0&quot;?&gt;</span>
<span class="nt">&lt;configuration&gt;</span>
<span class="nt">&lt;property&gt;</span>
<span class="hll"><span class="nt">&lt;name&gt;</span>yarn.nodemanager.aux-services<span class="nt">&lt;/name&gt;</span>
</span><span class="hll"><span class="nt">&lt;value&gt;</span>mapreduce_shuffle<span class="nt">&lt;/value&gt;</span>
</span><span class="nt">&lt;/property&gt;</span>
<span class="nt">&lt;property&gt;</span>
<span class="hll"><span class="nt">&lt;name&gt;</span>yarn.nodemanager.auxservices.mapreduce.shuffle.class<span class="nt">&lt;/name&gt;</span>
</span><span class="hll"><span class="nt">&lt;value&gt;</span>org.apache.hadoop.mapred.ShuffleHandler<span class="nt">&lt;/value&gt;</span>
</span><span class="nt">&lt;/property&gt;</span>
<span class="nt">&lt;/configuration&gt;</span>
</pre></div>
</div>
</li>
</ol>
</div>
<div class="section" id="configure-your-ssh-key">
<h2>Configure your SSH key</h2>
<ol class="arabic">
<li><p class="first">Create a SSH key. If you already have one, skip this step.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>sudo ssh-keygen -t rsa
</pre></div>
</div>
</li>
<li><p class="first">Copy the key to your authorized keys.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>sudo cat /root/.ssh/id_rsa.pub <span class="p">|</span> sudo tee -a /root/.ssh/authorized_keys
</pre></div>
</div>
</li>
<li><p class="first">Log into the localhost. If no password prompt appears, you are ready to
run the Hadoop daemons.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>sudo ssh localhost
</pre></div>
</div>
</li>
</ol>
</div>
<div class="section" id="run-the-hadoop-daemons">
<h2>Run the Hadoop daemons</h2>
<p>With all the configuration files properly edited, we are ready to start the
daemons.</p>
<p>When we format the <cite>NameNode</cite> server, it formats the meta-data related to
data nodes. Thus, all the information on the data nodes is lost and the nodes
can be reused for new data.</p>
<ol class="arabic">
<li><p class="first">Format the <cite>NameNode</cite> server with the following command:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>sudo hdfs namenode -format
</pre></div>
</div>
</li>
<li><p class="first">Start the DFS in <cite>NameNode</cite> and <cite>DataNodes</cite> with the following command:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>sudo start-dfs.sh
</pre></div>
</div>
</li>
<li><p class="first">The console output should be similar to:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">Starting namenodes on [localhost]</span>
<span class="go">The authenticity of host &#39;localhost (::1)&#39; can&#39;t be established.</span>
<span class="go">ECDSA key fingerprint is</span>
<span class="go">SHA256:97e+7TnomsS9W7GjFPjzY75HGBp+f1y6sA+ZFcOPIPU.</span>
<span class="go">Are you sure you want to continue connecting (yes/no)?</span>
</pre></div>
</div>
<p>Enter <cite>yes</cite> to continue.</p>
</li>
<li><p class="first">Start the <cite>YARN</cite> daemons <cite>ResourceManager</cite> and <cite>NodeManager</cite> with the
following command:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>sudo start-yarn.sh
</pre></div>
</div>
</li>
<li><p class="first">Ensure everything is running as expected with the following command:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>sudo jps
</pre></div>
</div>
</li>
<li><p class="first">The console output should be similar to:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">22674 DataNode</span>
<span class="go">26228 Jps</span>
<span class="go">22533 NameNode</span>
<span class="go">23046 ResourceManager</span>
<span class="go">22854 SecondaryNameNode</span>
<span class="go">23150 NodeManager</span>
</pre></div>
</div>
</li>
</ol>
</div>
<div class="section" id="run-the-mapreduce-wordcount-example">
<h2>Run the MapReduce wordcount example</h2>
<ol class="arabic">
<li><p class="first">Create the input directory.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>sudo hdfs dfs -mkdir -p /user/root/input
</pre></div>
</div>
</li>
<li><p class="first">Copy a file from the local file system to the HDFS.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>sudo hdfs dfs -copyFromLocal local-file /user/root/input
</pre></div>
</div>
</li>
<li><p class="first">Run the <cite>wordcount</cite> example.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>sudo hadoop jar /usr/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.0.jar wordcount input output
</pre></div>
</div>
</li>
<li><p class="first">Read output file “part-r-00000”. This file contains the number of times
each word appears in the file.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>sudo hdfs dfs -cat /user/root/output/part-r-00000
</pre></div>
</div>
</li>
</ol>
<p><strong>Congratulations!</strong></p>
<p>You successfully installed and setup a single node Hadoop cluster.
Additionally, you ran a simple wordcount example.</p>
<p>Your single node Hadoop cluster is up and running!</p>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="fmv.html" class="btn btn-neutral float-right" title="Use the function multi-version patch generator" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="azure.html" class="btn btn-neutral float-left" title="Run Clear Linux* OS using Microsoft Azure CLI 2.0" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019, many
      <span class="lastupdated">
        最后更新于 7月 24, 2019.
      </span>

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>


      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
  

<script type="text/javascript" src="../_static/tcs_theme.js"></script>



</body>
</html>